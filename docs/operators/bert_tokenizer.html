

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>BertTokenizer &mdash; Python Inference Script 1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Python Inference Script
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Model Authoring</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="a_list_of_operators.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/a_list_of_tutorials.html">Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../backends/cpython.html">CPython Backend üêç</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backends/libtorch.html">LibTorch Backend üî•</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backends/onnxruntime.html">ONNXRuntime Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backends/native_cpp_library.html">Native C++ Library</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">For Developers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dev/why_we_build_pyis.html">Why We Build PyIS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/build_from_source.html">Build from Source</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/house_keeping.html">House Keeping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/build_libtorch.html">Build LibTorch for JIT</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Python Inference Script</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>BertTokenizer</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/operators/bert_tokenizer.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="berttokenizer">
<h1>BertTokenizer<a class="headerlink" href="#berttokenizer" title="Permalink to this headline">¬∂</a></h1>
<p>BertTokenizer operator is an adapted version from official Hugging face BertTokenizerFast implementation.</p>
<div class="section" id="summary-of-the-tokenizers-huggingface">
<h2>Summary of the tokenizers (ü§ó <a class="reference external" href="https://huggingface.co/transformers/tokenizer_summary.html#summary-of-the-tokenizers">Huggingface</a>)<a class="headerlink" href="#summary-of-the-tokenizers-huggingface" title="Permalink to this headline">¬∂</a></h2>
<p>Tokenizing a text is splitting it into words or subwords, which then are converted to ids through a look-up table. Converting words or subwords to ids is straightforward.</p>
<p>Space and punctuation tokenization and rule-based tokenization are both examples of word tokenization, which is loosely defined as splitting sentences into words. While it‚Äôs the most intuitive way to split texts into smaller chunks, this tokenization method can lead to problems for massive text corpora. In this case, space and punctuation tokenization usually generates a very big vocabulary (the set of all unique words and tokens used). E.g., Transformer XL uses space and punctuation tokenization, resulting in a vocabulary size of 267,735!</p>
<p>While character tokenization is very simple and would greatly reduce memory and time complexity it makes it much harder for the model to learn meaningful input representations. E.g. learning a meaningful context-independent representation for the letter ‚Äút‚Äù is much harder than learning a context-independent representation for the word ‚Äútoday‚Äù. Therefore, character tokenization is often accompanied by a loss of performance. So to get the best of both worlds, transformers models use a hybrid between word-level and character-level tokenization called subword tokenization.</p>
<p>There are three main types of tokenizers used in Transformers:</p>
<ul class="simple">
<li><p>Byte-Pair Encoding (BPE)</p></li>
<li><p>WordPiece, used by BERT, DistilBERT, and Electra</p></li>
<li><p>SentencePiece</p></li>
</ul>
</div>
<div class="section" id="apis">
<h2>APIs<a class="headerlink" href="#apis" title="Permalink to this headline">¬∂</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pyis.python.ops.BertTokenizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">pyis.python.ops.</span></span><span class="sig-name descname"><span class="pre">BertTokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ops.BertTokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_file</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_lower_case</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_basic_tokenize</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cls_token</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'[CLS]'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep_token</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'[SEP]'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unk_token</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'[UNK]'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'[PAD]'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_token</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'[MASK]'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenize_chinese_chars</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strip_accents</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">suffix_indicator</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'##'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#pyis.python.ops.BertTokenizer" title="Permalink to this definition">¬∂</a></dt>
<dd><p>For tokenizing text into id sequences (same as Bert Tokenizer Fast)</p>
<p>Create a BertTokenizer instance</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_file_path</strong> (<em>str</em>) ‚Äì path to the vocabulary file</p></li>
<li><p><strong>do_lower_case</strong> (<em>bool</em>) ‚Äì should the tokenizer turn string into lowercase, default to true</p></li>
<li><p><strong>do_basic_tokenize</strong> (<em>bool</em>) ‚Äì should the tokenizer do basic tokenize first, default to true</p></li>
<li><p><strong>cls_token</strong> (<em>str</em>) ‚Äì start token symbol, default to ‚Äò[CLS]‚Äô</p></li>
<li><p><strong>sep_token</strong> (<em>str</em>) ‚Äì end token symbol, default to ‚Äò[SEP]‚Äô</p></li>
<li><p><strong>unknown_token</strong> (<em>str</em>) ‚Äì unknown token symbol, default to ‚Äò[UNK]‚Äô</p></li>
<li><p><strong>pad_token</strong> (<em>str</em>) ‚Äì padding token symbol, default to ‚Äò[PAD]‚Äô</p></li>
<li><p><strong>mask_token</strong> (<em>str</em>) ‚Äì mask token symbol, default to ‚Äò[MASK]‚Äô</p></li>
<li><p><strong>tokenize_chinese_chars</strong> (<em>bool</em>) ‚Äì should the tokenizer tokenize chinese chars, default to true</p></li>
<li><p><strong>strip_accents</strong> (<em>bool</em>) ‚Äì shoule the tokenizer strip accents. default to false</p></li>
<li><p><strong>suffix_indicator</strong> (<em>str</em>) ‚Äì string prefix indicates the token is a suffix of previous token. default to ‚Äò##‚Äô</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pyis.python.ops.BertTokenizer.convert_id_to_token">
<span class="sig-name descname"><span class="pre">convert_id_to_token</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ops.BertTokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#pyis.python.ops.BertTokenizer.convert_id_to_token" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Convert token id to token text</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>id</strong> (<em>int</em>) ‚Äì token id</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output token text to the given id</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyis.python.ops.BertTokenizer.convert_token_to_id">
<span class="sig-name descname"><span class="pre">convert_token_to_id</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ops.BertTokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#pyis.python.ops.BertTokenizer.convert_token_to_id" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Convert token text to token id</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>token</strong> (<em>str</em>) ‚Äì token text</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output token id to the given token text</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyis.python.ops.BertTokenizer.decode">
<span class="sig-name descname"><span class="pre">decode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ops.BertTokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ids</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#pyis.python.ops.BertTokenizer.decode" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Decode a list of token indices, turn them into a string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ids</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) ‚Äì list of token indices</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output the corresponding string to the list.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyis.python.ops.BertTokenizer.encode">
<span class="sig-name descname"><span class="pre">encode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ops.BertTokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000000000000000</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pyis.python.ops.BertTokenizer.encode" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Tokenize the input string and return list of token indices (ids).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>str</em>) ‚Äì input query to be tokenized</p></li>
<li><p><strong>max_length</strong> (<em>int</em>) ‚Äì max acceptable length for truncation. default to 1e15</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output list of token indices (ids)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyis.python.ops.BertTokenizer.encode2">
<span class="sig-name descname"><span class="pre">encode2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ops.BertTokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str2</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000000000000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncation_strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'longest_first'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pyis.python.ops.BertTokenizer.encode2" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Tokenize two input strings and return list of token indices (ids).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>str1</strong> (<em>str</em>) ‚Äì input query to be tokenized</p></li>
<li><p><strong>str2</strong> (<em>str</em>) ‚Äì input query to be tokenized</p></li>
<li><p><strong>max_length</strong> (<em>int</em>) ‚Äì max acceptable length for truncation. default to 1e15</p></li>
<li><p><strong>truncation_strategy</strong> (<em>str</em>) ‚Äì truncation strategy, coule be ‚Äòlongest_first‚Äô (default), ‚Äòlongest_from_back‚Äô, ‚Äòonly_first‚Äô and ‚Äòonly_second‚Äô</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output list of token indices (ids)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyis.python.ops.BertTokenizer.encode_plus">
<span class="sig-name descname"><span class="pre">encode_plus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ops.BertTokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000000000000000</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pyis.python.ops.BertTokenizer.encode_plus" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Tokenize the input string and return list of token indices (ids), type ids and attention mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>str</em>) ‚Äì input query to be tokenized</p></li>
<li><p><strong>max_length</strong> (<em>int</em>) ‚Äì max acceptable length for truncation. default to 1e15</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output list of tuple, each tuple contains (ids, type ids, attention mask)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyis.python.ops.BertTokenizer.encode_plus2">
<span class="sig-name descname"><span class="pre">encode_plus2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ops.BertTokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">str2</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000000000000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncation_strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'longest_first'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pyis.python.ops.BertTokenizer.encode_plus2" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Tokenize two input strings and return list of token indices (ids), type ids and attention mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>str1</strong> (<em>str</em>) ‚Äì input query to be tokenized</p></li>
<li><p><strong>str2</strong> (<em>str</em>) ‚Äì input query to be tokenized</p></li>
<li><p><strong>max_length</strong> (<em>int</em>) ‚Äì max acceptable length for truncation. default to 1e15</p></li>
<li><p><strong>truncation_strategy</strong> (<em>str</em>) ‚Äì truncation strategy, coule be ‚Äòlongest_first‚Äô (default), ‚Äòlongest_from_back‚Äô, ‚Äòonly_first‚Äô and ‚Äòonly_second‚Äô</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output list of tuple, each tuple contains (ids, type ids, attention mask)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyis.python.ops.BertTokenizer.tokenize">
<span class="sig-name descname"><span class="pre">tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">ops.BertTokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#pyis.python.ops.BertTokenizer.tokenize" title="Permalink to this definition">¬∂</a></dt>
<dd><p>Tokenize the input string and return list of tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>query</strong> (<em>str</em>) ‚Äì input query to be tokenized</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output list of tokens</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">¬∂</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) Microsoft Corporation. All rights reserved.</span>
<span class="c1"># Licensed under the MIT license.</span>

<span class="kn">from</span> <span class="nn">pyis.python</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="n">tokenizer</span><span class="p">:</span> <span class="n">ops</span><span class="o">.</span><span class="n">BertTokenizer</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">BertTokenizer</span><span class="p">(</span><span class="s1">&#39;vocab.txt&#39;</span><span class="p">)</span>

<span class="n">query</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;what is the time in US?&#39;</span>

<span class="n">token_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Inference Team, STCA, Microsoft.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>